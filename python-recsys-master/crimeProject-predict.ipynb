{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "import sys\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas\n",
    "import sklearn.datasets as sk_data\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from recsys.algorithm.factorize import SVD\n",
    "\n",
    "import warnings\n",
    "from sklearn.ensemble.forest import DecisionTreeRegressor as tree\n",
    "import json\n",
    "\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    parsing one again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268056\n",
      "[u'sid', u'id', u'position', u'created_at', u'created_meta', u'updated_at', u'updated_meta', u'meta', u'COMPNOS', u'NatureCode', u'INCIDENT_TYPE_DESCRIPTION', u'MAIN_CRIMECODE', u'REPTDISTRICT', u'REPORTINGAREA', u'FROMDATE', u'WEAPONTYPE', u'Shooting', u'DOMESTIC', u'SHIFT', u'Year', u'Month', u'DAY_WEEK', u'UCRPART', u'X', u'Y', u'STREETNAME', u'XSTREETNAME', u'Location']\n",
      "  INCIDENT_TYPE_DESCRIPTION             FROMDATE  \\\n",
      "0      RESIDENTIAL BURGLARY  2012-07-08T06:00:00   \n",
      "1        AGGRAVATED ASSAULT  2012-07-08T06:03:00   \n",
      "2                   ROBBERY  2012-07-08T06:26:00   \n",
      "3       COMMERCIAL BURGLARY  2012-07-08T06:56:00   \n",
      "4                   ROBBERY  2012-07-08T07:15:00   \n",
      "\n",
      "                                         Location  \n",
      "0  [None, 42.34638135, -71.10379454, None, False]  \n",
      "1  [None, 42.31684135, -71.07458456, None, False]  \n",
      "2  [None, 42.34284135, -71.09698955, None, False]  \n",
      "3   [None, 42.3164411, -71.06582908, None, False]  \n",
      "4  [None, 42.27051636, -71.11989955, None, False]  \n",
      "268056 15\n",
      "268056 268056 268056\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('../boston-rows.json') as data_file:    \n",
    "    bostonjson = json.load(data_file)\n",
    "\n",
    "print len(bostonjson['data'])\n",
    "\n",
    "columnlist = []\n",
    "for col in bostonjson['meta']['view']['columns']:\n",
    "    columnlist.append(col['name'])\n",
    "\n",
    "bostondf = pd.DataFrame(bostonjson['data'])\n",
    "bostondf.columns = columnlist\n",
    "print columnlist\n",
    "print bostondf.head()[['INCIDENT_TYPE_DESCRIPTION','FROMDATE','Location']]\n",
    "\n",
    "#latlist = map(lambda k: k[1], bostondf['Location'])\n",
    "#longlist = map(lambda k: k[2], bostondf['Location'])\n",
    "\n",
    "types = map(lambda k: k.lower(), bostondf['INCIDENT_TYPE_DESCRIPTION'])\n",
    "hours = map(lambda k: k.split(\"T\")[1].split(\":\")[0], bostondf['FROMDATE'])\n",
    "days = map(lambda k: k, bostondf['DAY_WEEK'])\n",
    "distrs = map(lambda k: k, bostondf['REPTDISTRICT'])\n",
    "print len(hours), len(list(set(distrs)))\n",
    "\n",
    "hourlist = []\n",
    "daylist = []\n",
    "distrlist = []\n",
    "typelist = []\n",
    "\n",
    "#print types[0], hours[0], days[0], distrs[10000]\n",
    "print len(hours), len(types), len(distrs)\n",
    "for i in xrange(len(hours)):\n",
    "    \n",
    "    if types[i] != 'val' and distrs[i] and distrs[i] != 'NULL':\n",
    "        hourlist.append(hours[i])\n",
    "        daylist.append(days[i] )\n",
    "        distrlist.append(distrs[i])\n",
    "        typelist.append(types[i])\n",
    "\n",
    "typeCnt = Counter(typelist)\n",
    "print len(typeCnt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILD TREE AND TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Type of Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "daydict = {\"monday\":1, \"tuesday\":2, \"wednesday\":3, \"thursday\":4, \"friday\":5, \"saturday\":6, \"sunday\":7}\n",
    "\n",
    "typeX = []\n",
    "typey = []\n",
    "\n",
    "inTypefd = open(\"../data/Boston-parse-type.dat.input\",\"r\")\n",
    "for l in inTypefd.readlines():\n",
    "    row = l.split(\"::\")\n",
    "    typeX.append([hash(row[0]),daydict[row[1].lower()]])\n",
    "    typey.append(row[2][:-1])\n",
    "inTypefd.close()\n",
    "\n",
    "timeX = []\n",
    "timey = []\n",
    "\n",
    "inTimefd = open(\"../data/Boston-parse-time.dat.input\",\"r\")\n",
    "for l in inTimefd.readlines():\n",
    "    row = l.split(\"::\")\n",
    "    timeX.append([hash(row[0]),daydict[row[1].lower()]])\n",
    "    timey.append(row[2][:-1])\n",
    "inTimefd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1', 'Sunday', '41\\n']\n"
     ]
    }
   ],
   "source": [
    "trainTypeSet = []\n",
    "\n",
    "trainTypefd = open(\"../data/Boston-parse-type.dat.trainerr\",\"r\")\n",
    "for l in trainTypefd.readlines():\n",
    "    row = l.split(\"::\")\n",
    "    trainTypeSet.append(row)\n",
    "trainTypefd.close()\n",
    "print trainTypeSet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaf 22 None 0.0 : 0.368219286321\n",
      "leaf 23 22 8470.05177712 : 0.368219286321\n",
      "leaf 24 22 8470.05177712 : 0.368219286321\n",
      "leaf 25 22 8470.05177712 : 0.368219286321\n",
      "leaf 26 22 8470.05177712 : 0.368219286321\n",
      "leaf 27 22 8470.05177712 : 0.368219286321\n",
      "leaf 28 22 8470.05177712 : 0.368219286321\n",
      "leaf 29 22 8470.05177712 : 0.368219286321\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "\n",
    "glerr = float('inf')\n",
    "optLeaftype, optDepthtype = None, None\n",
    "rate = 0.0\n",
    "\n",
    "for leaf in xrange(22, 30):\n",
    "    print 'leaf', leaf, optLeaftype, rate,\":\",\n",
    "    \"\"\"\n",
    "    Predict with each model and find minimum error parameters\n",
    "    \"\"\"\n",
    "    for depth in range(5, 16, 2):\n",
    "        model = tree(min_samples_leaf=leaf, max_depth=depth)\n",
    "        model = model.fit(typeX,typey)\n",
    "\n",
    "        err = 0.0\n",
    "        crCount = 0\n",
    "        for l in trainTypeSet:            \n",
    "            #print l\n",
    "            x = [hash(l[0]),daydict[l[1].lower()]]\n",
    "            \n",
    "            pred = model.predict(x)[0]\n",
    "            #print pred, l[2][:-1]\n",
    "            #sys.exit(0)\n",
    "            err += (pred-int(l[2][:-1]))**2\n",
    "            crCount +=1\n",
    "            \n",
    "        rate = 1.0*err/10000\n",
    "        if rate < glerr:\n",
    "            glerr = rate\n",
    "            \"\"\"\n",
    "            Later use these to build predicting model:\n",
    "            \"\"\"\n",
    "            optLeaftype, optDepthtype  = leaf, depth\n",
    "        \n",
    "    print (glerr/crCount)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 7\n"
     ]
    }
   ],
   "source": [
    "print optLeaftype, optDepthtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Time of crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1', 'Sunday', '2\\n']\n"
     ]
    }
   ],
   "source": [
    "trainTimeSet = []\n",
    "\n",
    "trainTimefd = open(\"../data/Boston-parse-time.dat.trainerr\",\"r\")\n",
    "for l in trainTimefd.readlines():\n",
    "    row = l.split(\"::\")\n",
    "    trainTimeSet.append(row)\n",
    "trainTimefd.close()\n",
    "print trainTimeSet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " leaf 20 None 0.0 : 0.00845426156186\n",
      "leaf 21 20 4.4648 : 0.00845426156186\n",
      "leaf 22 20 4.4648 : 0.00845426156186\n",
      "leaf 23 20 4.4648 : 0.00845426156186\n",
      "leaf 24 20 4.4648 : 0.00845426156186\n",
      "leaf 25 20 4.4648 : 0.00845426156186\n",
      "leaf 26 20 4.4648 : 0.00845426156186\n",
      "leaf 27 20 4.4648 : 0.00845426156186\n",
      "leaf 28 20 4.4648 : 0.00845426156186\n",
      "leaf 29 20 4.4648 : 0.00845426156186\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "\n",
    "glerr = float('inf')\n",
    "optLeaftime, optDepthtime = None, None\n",
    "rate = 0.0\n",
    "\n",
    "\n",
    "for leaf in xrange(20, 30):\n",
    "    print 'leaf', leaf, optLeaftime, rate,\":\",\n",
    "    \"\"\"\n",
    "    Predict with each model and find minimum error parameters\n",
    "    \"\"\"\n",
    "    for depth in range(5, 16, 2):\n",
    "        model = tree(min_samples_leaf=leaf, max_depth=depth)\n",
    "        model = model.fit(timeX,timey)\n",
    "\n",
    "        err = 0\n",
    "        nCount = 0\n",
    "        for l in trainTimeSet:                        \n",
    "            x = [hash(l[0]),daydict[l[1].lower()]]\n",
    "            \n",
    "            pred = round(model.predict(x)[0])\n",
    "            #print pred, l[2][:-1]\n",
    "            #sys.exit(0)\n",
    "            err += (pred-int(l[2][:-1]))**2\n",
    "            nCount += 1\n",
    "        rate = 1.0*err/10000\n",
    "        if rate < glerr:\n",
    "            glerr = rate\n",
    "            \"\"\"\n",
    "            Later use these to build predicting model:\n",
    "            \"\"\"\n",
    "            optLeaftime, optDepthtime  = leaf, depth\n",
    "        \n",
    "    print (glerr/nCount)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 5\n"
     ]
    }
   ],
   "source": [
    "print optLeaftime, optDepthtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICT USING NAIVE BAYES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'22', u'02', u'03', u'00', u'01', u'06', u'07', u'04', u'05', u'08', u'09', u'20', u'21', u'11', u'10', u'13', u'12', u'15', u'14', u'17', u'16', u'19', u'18', u'23', u'Monday', u'Tuesday', u'Friday', u'Wednesday', u'Thursday', u'Sunday', u'Saturday', u'A15', u'D14', u'A7', u'E18', u'E13', u'A1', u'D4', u'HTU', u'B2', u'B3', u'E5', u'C11', u'C6']\n",
      "   00  01  02  03  04  05  06  07  08  09          ...           B3  C11  C6  \\\n",
      "0   0   0   0   0   0   0   1   0   0   0          ...            0    0   0   \n",
      "1   0   0   0   0   0   0   1   0   0   0          ...            0    0   0   \n",
      "2   0   0   0   0   0   0   1   0   0   0          ...            0    0   0   \n",
      "3   0   0   0   0   0   0   1   0   0   0          ...            0    0   0   \n",
      "4   0   0   0   0   0   0   0   1   0   0          ...            0    0   0   \n",
      "\n",
      "   D14  D4  E13  E18  E5  HTU                 crime  \n",
      "0    0   1    0    0   0    0  residential burglary  \n",
      "1    0   0    0    0   0    0    aggravated assault  \n",
      "2    0   1    0    0   0    0               robbery  \n",
      "3    0   0    0    0   0    0   commercial burglary  \n",
      "4    0   0    0    1   0    0               robbery  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "#Get binarized weekdays, districts, and hours.\n",
    "days = pd.get_dummies(daylist)\n",
    "district = pd.get_dummies(distrlist)\n",
    "hour = pd.get_dummies(hourlist) \n",
    " \n",
    "#Build new array\n",
    "train_data = pd.concat([hour, days, district], axis=1)\n",
    "train_data['crime']=typelist\n",
    "\n",
    "colList = list(set(hour))+list(set(days))+list(set(district))\n",
    "print colList\n",
    "print train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', 'A15', 'D14', 'A7', 'E18', 'E13', 'A1', 'D4', 'HTU', 'B2', 'B3', 'E5', 'C11', 'C6'] 20\n",
      "        00  01  02  03  04  05  06  07  08  09             ...              \\\n",
      "163206   0   0   0   0   0   0   0   0   0   0             ...               \n",
      "217067   0   0   0   0   0   0   0   0   0   0             ...               \n",
      "177201   0   0   0   0   0   0   0   0   0   0             ...               \n",
      "193071   0   0   0   0   0   0   0   0   0   0             ...               \n",
      "187624   0   0   0   0   0   0   0   0   0   0             ...               \n",
      "\n",
      "        B3  C11  C6  D14  D4  E13  E18  E5  HTU                       crime  \n",
      "163206   0    0   0    0   1    0    0   0    0              weapons charge  \n",
      "217067   0    0   0    1   0    0    0   0    0                     invprop  \n",
      "177201   0    0   0    0   0    0    0   0    0                     invprop  \n",
      "193071   0    0   0    0   0    0    0   0    0              weapons charge  \n",
      "187624   0    0   0    0   1    0    0   0    0  larceny from motor vehicle  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "#Repeat for test data\n",
    "Btest = defaultdict(list)\n",
    "testTypefd = open(\"../data/Boston.dat.testpair\",\"r\")\n",
    "for l in testTypefd.readlines():\n",
    "    row = l.split(\"::\")\n",
    "    Btest['District'].append(row[0])\n",
    "    Btest['DayOfWeek'].append(row[1])\n",
    "    Btest['Hour'].append(row[2][:-1])\n",
    "\n",
    "    \n",
    "testTypefd.close()\n",
    "\n",
    "days = pd.get_dummies(Btest['DayOfWeek'])\n",
    "district = pd.get_dummies(Btest['District'])\n",
    "hour = pd.get_dummies(Btest['Hour']) \n",
    "\n",
    "test_data = pd.concat([hour, days, district], axis=1)\n",
    "\n",
    "training, validation = train_test_split(train_data, train_size=.60)\n",
    "\n",
    "commonCrimes = map(lambda k: k[0].lower(), typeCnt.most_common(20))\n",
    "\n",
    "features = ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday',\n",
    " 'Wednesday']+list(set(district))\n",
    "print features, len(features)\n",
    "training, validation = train_test_split(train_data, train_size=.60)\n",
    "print training.head()\n",
    "model = BernoulliNB()\n",
    "model.fit(training[features], training['crime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "[u'other larceny' u'other larceny' u'other larceny' u'simple assault'\n",
      " u'simple assault' u'other larceny' u'vandalism' u'other larceny'\n",
      " u'other larceny' u'medassist' u'other larceny' u'vandalism'\n",
      " u'simple assault' u'simple assault' u'simple assault' u'other larceny'\n",
      " u'medassist' u'medassist' u'simple assault' u'simple assault'\n",
      " u'simple assault' u'other larceny' u'simple assault' u'simple assault'\n",
      " u'towed' u'simple assault' u'simple assault' u'medassist' u'medassist'\n",
      " u'other larceny' u'simple assault' u'other larceny' u'other larceny'\n",
      " u'medassist' u'medassist' u'medassist' u'vandalism' u'medassist'\n",
      " u'medassist' u'medassist' u'simple assault' u'other larceny' u'medassist'\n",
      " u'other larceny' u'other larceny' u'medassist' u'medassist'\n",
      " u'simple assault' u'other larceny' u'other larceny']\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#predicted = np.array(model.predict_proba(validation[features]))\n",
    "predicted = np.array(model.predict(validation[features]))\n",
    "print type(predicted)\n",
    "print predicted[0:50]\n",
    "#log_loss(validation['crime'], predicted) \n",
    "\n",
    "\"\"\"\n",
    "#Logistic Regression for comparison\n",
    "model = LogisticRegression(C=.01)\n",
    "model.fit(training[features], training['crime'])\n",
    "predicted = np.array(model.predict_proba(validation[features]))\n",
    "#log_loss(validation['crime'], predicted) \n",
    "print predicted[0:50]\n",
    "\n",
    "\"\"\"\n",
    "print \"Done\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'vandalism' u'medassist' u'other larceny' u'other larceny'\n",
      " u'other larceny' u'medassist' u'other larceny' u'vandalism'\n",
      " u'other larceny' u'simple assault' u'other larceny' u'medassist'\n",
      " u'other larceny' u'medassist' u'other larceny' u'towed' u'medassist'\n",
      " u'other larceny' u'medassist' u'other larceny' u'simple assault'\n",
      " u'simple assault' u'other larceny' u'medassist' u'medassist' u'medassist'\n",
      " u'medassist' u'other larceny' u'other larceny' u'medassist'\n",
      " u'other larceny' u'simple assault' u'other larceny' u'medassist'\n",
      " u'medassist' u'medassist' u'medassist' u'medassist' u'medassist'\n",
      " u'medassist' u'other larceny' u'other larceny' u'other larceny'\n",
      " u'other larceny' u'medassist' u'other larceny' u'other larceny'\n",
      " u'simple assault' u'other larceny' u'other larceny']\n"
     ]
    }
   ],
   "source": [
    "newmodel = BernoulliNB()\n",
    "newmodel.fit(train_data[features], train_data['crime'])\n",
    "predicted = newmodel.predict(test_data[features])\n",
    "print predicted[:50]\n",
    "\n",
    "#Write results\n",
    "#result=pd.DataFrame(predicted)\n",
    "#result.to_csv('testResult.csv', index = True, index_label = 'Id' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   00  01  02  03  04  05  06  07  08  09          ...           B3  C11  C6  \\\n",
      "0   0   0   0   0   0   0   1   0   0   0          ...            0    0   0   \n",
      "1   0   0   0   0   0   0   1   0   0   0          ...            0    0   0   \n",
      "2   0   0   0   0   0   0   1   0   0   0          ...            0    0   0   \n",
      "3   0   0   0   0   0   0   1   0   0   0          ...            0    0   0   \n",
      "4   0   0   0   0   0   0   0   1   0   0          ...            0    0   0   \n",
      "\n",
      "   D14  D4  E13  E18  E5  HTU                 crime  \n",
      "0    0   1    0    0   0    0  residential burglary  \n",
      "1    0   0    0    0   0    0    aggravated assault  \n",
      "2    0   1    0    0   0    0               robbery  \n",
      "3    0   0    0    0   0    0   commercial burglary  \n",
      "4    0   0    0    1   0    0               robbery  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICT USING TREES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Type of Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = tree(min_samples_leaf=optLeaftype, max_depth=optDepthtype)\n",
    "model = model.fit(typeX,typey)\n",
    "\n",
    "testTypefd = open(\"../data/Boston.dat.testpair\",\"r\")\n",
    "resfd = open(\"../results/Boston-type-pred.dat\",\"w\")\n",
    "for l in testTypefd.readlines():\n",
    "    row = l.split(\"::\")\n",
    "    \n",
    "    x = [hash(row[0]),daydict[row[1][:-1].lower()]]\n",
    "    pred = int(round(model.predict(x)[0]))\n",
    "    #resfd.write(row[0]+\"-\"+row[1][:-1]+\"-\"+str(pred)+\"\\n\")\n",
    "    resfd.write(row[0]+\"-\"+row[1][:-1]+\"-\"+list(typeCnt.keys())[pred]+\"\\n\")\n",
    "    #print list(typeCnt.keys())[pred]\n",
    "    #print pred\n",
    "    #break\n",
    "    \n",
    "testTypefd.close()\n",
    "resfd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Time of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = tree(min_samples_leaf=optLeaftime, max_depth=optDepthtime)\n",
    "model = model.fit(timeX,timey)\n",
    "\n",
    "testTypefd = open(\"../data/Boston.dat.testpair\",\"r\")\n",
    "resfd = open(\"../results/Boston-time-pred.dat\",\"w\")\n",
    "\n",
    "for l in testTypefd.readlines():\n",
    "    row = l.split(\"::\")\n",
    "    \n",
    "    x = [hash(row[0]),daydict[row[1][:-1].lower()]]\n",
    "    pred = model.predict(x)[0]*6\n",
    "    resfd.write(row[0]+\"-\"+row[1][:-1]+\"-\"+str(pred)+\"\\n\")\n",
    "    #print pred\n",
    "    #break\n",
    "testTypefd.close()\n",
    "resfd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILD MODEL AND TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svdK = 20\n",
    "modelCrime = SVD()\n",
    "modelCrime.load_data(filename='../data/Boston-parse-type.dat.input', sep='::', format={'col':0, 'row':1, 'value':2, 'ids': str})\n",
    "modelCrime.compute(k=svdK, min_values=6, pre_normalize=None, mean_center=True, post_normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1', 'Sunday', '41\\n'] 32\n"
     ]
    }
   ],
   "source": [
    "trainTypefd = open(\"../data/Boston-parse-type.dat.trainerr\",\"r\")\n",
    "for l in trainTypefd.readlines():\n",
    "    row = l.split(\"::\")\n",
    "    try:        \n",
    "        predTime = int(round(modelCrime.predict(row[1], row[0])%125))\n",
    "        print row, predTime\n",
    "        break\n",
    "    except KeyError:\n",
    "        print '.',\n",
    "        continue\n",
    "\n",
    "trainTypefd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelCrimeTime = SVD()\n",
    "modelCrimeTime.load_data(filename='../data/Boston-parse-time.dat.input', sep='::', format={'col':0, 'row':1, 'value':2, 'ids': str})\n",
    "modelCrimeTime.compute(k=svdK, min_values=6, pre_normalize=None, mean_center=True, post_normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1', 'Sunday', '2\\n'] 1.0\n"
     ]
    }
   ],
   "source": [
    "#../data/Boston-parse-time.dat.trainerr\n",
    "trainTimefd = open(\"../data/Boston-parse-time.dat.trainerr\",\"r\")\n",
    "for l in trainTimefd.readlines():\n",
    "    row = l.split(\"::\")\n",
    "    try:\n",
    "        predTime = str(round(modelCrimeTime.predict(row[1], row[0])%7))\n",
    "        print row, predTime\n",
    "        \n",
    "        break\n",
    "    except KeyError:\n",
    "        print '.',\n",
    "        continue\n",
    "\n",
    "\n",
    "trainTimefd.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE PREDICTION PAIRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Done during parsing phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#../data/Boston-parse-time.dat.test\n",
    "#D4:Sunday\n",
    "#C6:Sunday\n",
    "#E5:Sunday...\n",
    "timePred = open(\"../results/recsys-Boston-time-pred.dat\",\"w\")\n",
    "testTimefd = open(\"../data/Boston.dat.testpair\",\"r\")\n",
    "for l in testTimefd.readlines():\n",
    "    row = l.split(\"::\")\n",
    "    try:        \n",
    "        predTime = str(modelCrimeTime.predict(row[1][:-1], row[0])%7)\n",
    "        timePred.write(row[0]+\"-\"+row[1][:-1]+\",\"+predTime+\"\\n\")      \n",
    "        #break\n",
    "    except KeyError:\n",
    "        #print row, '....',\n",
    "        continue\n",
    "\n",
    "\n",
    "testTimefd.close()\n",
    "timePred.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "typePred = open(\"../results/recsys-Boston-type-pred.dat\",\"w\")\n",
    "typeTestfd = open(\"../data/Boston.dat.testpair\",\"r\")\n",
    "\n",
    "for l in typeTestfd.readlines():\n",
    "    row = l.split(\"::\")\n",
    "    try:        \n",
    "        predType = modelCrime.predict(row[1][:-1], row[0])%100\n",
    "        #print predType,\n",
    "        \n",
    "        #typePred.write(row[0]+\"-\"+row[1][:-1]+\",\"+str(predType)+\"\\n\") \n",
    "        typePred.write(row[0]+\"-\"+row[1][:-1]+\"-\"+list(typeCnt.keys())[int(predType)]+\"\\n\")\n",
    "        \n",
    "    except KeyError:\n",
    "        #print row, '....',\n",
    "        continue\n",
    "\n",
    "\n",
    "typeTestfd.close()\n",
    "typePred.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSE PREDICTIONS (Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rmse/classiff error?..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
